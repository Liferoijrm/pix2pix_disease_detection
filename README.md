# ğŸŒ± DiagnÃ³stico de DoenÃ§as em Folhas usando IA Generativa  
### Projeto 2 â€” IntroduÃ§Ã£o Ã  InteligÃªncia Artificial (UnB, 2025/2)

**Professor:** DÃ­bio L. Borges 
**Departamento de CiÃªncia da ComputaÃ§Ã£o â€” Universidade de BrasÃ­lia**

---

## ğŸ“Œ VisÃ£o Geral

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o completa do **Projeto 2**, cujo objetivo Ã© desenvolver um sistema de detecÃ§Ã£o de anomalias em folhas de plantas utilizando um mÃ©todo **nÃ£o supervisionado** baseado em **reconstruÃ§Ã£o de cores**, conforme descrito no artigo:

**KATAFUCHI, Ryoya; TOKUNAGA, Terumasa.**  
*Image-based Plant Disease Diagnosis with Unsupervised Anomaly Detection Based on Reconstructability of Colors.*  
arXiv preprint arXiv:2011.14306, 2020.  
ğŸ”— **PDF:** https://arxiv.org/pdf/2011.14306  

O mÃ©todo utiliza um modelo **pix2pix (GAN condicional)** para reconstruir imagens coloridas de folhas saudÃ¡veis a partir de suas versÃµes em tons de cinza. Em seguida, calcula-se um Ã­ndice perceptual de anomalia usando **CIEDE2000**, indicando possÃ­veis regiÃµes sintomÃ¡ticas.

AlÃ©m disso, o projeto inclui **visualizaÃ§Ã£o por Grad-CAM**, conforme:

**SELVARAJU, R.R. et al.**  
*Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization.*  
ICCV, 2017.  

---

## ğŸš€ Objetivos do Projeto

- Treinar o modelo **pix2pix** usando **50 imagens saudÃ¡veis**.
- Reconstruir cores de imagens saudÃ¡veis e doentes.
- Calcular anomalia usando **CIEDE2000** por pixel.
- Gerar mapas de calor das regiÃµes sintomÃ¡ticas.
- Avaliar o modelo seguindo as mÃ©tricas do artigo:
  - âœ”ï¸ AUC-ROC   
  - âœ”ï¸ AcurÃ¡cia
  - âœ”ï¸ PrecisÃ£o  
  - âœ”ï¸ Recall  
  - âœ”ï¸ F1-score  
- Aplicar **Grad-CAM** ao modelo para identificar regiÃµes relevantes.

---

## ğŸ§  Metodologia Utilizada

### **1. ReconstruÃ§Ã£o de Cores com pix2pix**
ConfiguraÃ§Ã£o e hiperparÃ¢metros

- **Gerador:** U-Net com *skip connections*  
- **Discriminador:** PatchGAN 70Ã—70 
- **Loss:** GAN + L1 (Î» = 5)  
- **Otimizador:** Adam  
  - lr = 0.00015  
  - Î²1 = 0.5  

### **2. DetecÃ§Ã£o de Anomalias com CIEDE2000**
- Para cada pixel:
  - DiferenÃ§a perceptual entre imagem original e reconstruÃ­da
- Soma dos valores gera o **Ã­ndice de anomalia**:
  - ğŸ”´ Alto â†’ possÃ­vel regiÃ£o doente  
  - ğŸŸ¢ Baixo â†’ regiÃ£o saudÃ¡vel  

### **3. VisualizaÃ§Ã£o com Grad-CAM**
Aplicada ao modelo para destacar regiÃµes decisivas para as previsÃµes.

---

## ğŸ“Š MÃ©tricas (mesmos moldes do artigo)

- **AUC-ROC**
- **AcurÃ¡cia**
- **PrecisÃ£o**
- **Recall**
- **F1-score**
- **Histogramas do Ã­ndice de anomalia**

As mÃ©tricas utilizam:

- 50 imagens saudÃ¡veis (teste)
- 100 imagens doentes (teste)

---

## ğŸ› ï¸ Como Executar

Para garantir que todas as dependÃªncias do PyTorch e pacotes de visualizaÃ§Ã£o sejam instaladas corretamente, Ã© **fortemente recomendado** utilizar um ambiente virtual, como **Conda** ou **Miniconda**.

### 1. ğŸ Configurar o Ambiente Conda

Instale o Conda/Miniconda (se ainda nÃ£o tiver) e crie o ambiente usando o arquivo de especificaÃ§Ã£o fornecido:

```bash
# Crie o ambiente Conda a partir do arquivo environment.yml
conda env create -f environment.yml

# Ative o novo ambiente
conda activate <nome_do_seu_ambiente>
```

### 2. ğŸ“ Estrutura de Dados

Certifique-se de que seu dataset esteja organizado no formato **pix2pix** no diretÃ³rio `datasets/leaf_disease_detection`.

### 3. ğŸš€ Executar os Scripts

Os principais *scripts* de inferÃªncia e visualizaÃ§Ã£o estÃ£o localizados na pasta `scripts/`. O caminho para a raiz dos dados (`--dataroot`) deve ser especificado:

#### A. Testar o Modelo em Todo o Conjunto de Imagens

Executa a inferÃªncia completa, reconstruindo todas as imagens do conjunto de teste, calculando o CIEDE2000 e salvando os resultados em results/.

```bash
python scripts/test_model.py --dataroot ./datasets/leaf_disease_detection
```

#### B. Testar o Modelo em Uma Ãšnica Imagem

Permite verificar a reconstruÃ§Ã£o e o mapa CIEDE2000 de uma imagem especÃ­fica â€” Ãºtil para anÃ¡lise qualitativa.

```bash
python scripts/test_single_image.py
--dataroot ./datasets/leaf_disease_detection
--path "../datasets/leaf_disease_detection/test/doentes/a988-992_ab_0.jpg"
```

#### C. Gerar VisualizaÃ§Ãµes Grad-CAM

Gera visualizaÃ§Ãµes Grad-CAM das camadas convolucionais do discriminador, permitindo interpretar quais regiÃµes influenciam sua decisÃ£o.

```bash
python scripts/show_GradCAM.py --dataroot ./datasets/leaf_disease_detection
```

#### D. Treinar o Modelo Pix2Pix

Executa o processo completo de treinamento, salvando os checkpoints em checkpoints/.

```bash
python train.py
--dataroot D:/pytorch-CycleGAN-and-pix2pix/datasets/leaf_disease_detection
--name pix2pix_final_v3
--model colorization
--dataset_mode colorization
--direction AtoB
--lr 0.00015
--lambda_L1 5.0
--beta1 0.5
--n_epochs 100
--n_epochs_decay 50
--netG unet_256
--netD basic
--num_threads 0
```

---

# ğŸ¨ Exemplos de VisualizaÃ§Ã£o

### ğŸ”¹ ReconstruÃ§Ã£o via pix2pix

| Original (Preto e Branco) | Original (RGB) | ReconstruÃ­da (RGB) | Mapa CIEDE2000 |
| :---: | :---: | :---: | :---: |
| ![Imagem em tons de cinza](results/test_single_leaf/reconstruction_a988-992_ab_0/input_grayscale_256.png) | ![Imagem RGB original](results/test_single_leaf/reconstruction_a988-992_ab_0/original_rgb_256.png) | ![Imagem RGB reconstruÃ­da](results/test_single_leaf/reconstruction_a988-992_ab_0/reconstructed_rgb_256.png) | ![Mapa CIEDE2000](results/test_single_leaf/reconstruction_a988-992_ab_0/ciede_heatmap_256.png) |
| **LocalizaÃ§Ã£o:** `../results/.../input_grayscale_256.png` | **LocalizaÃ§Ã£o:** `../results/.../original_rgb_256.png` | **LocalizaÃ§Ã£o:** `../results/.../reconstructed_rgb_256.png` | **LocalizaÃ§Ã£o:** `../results/.../ciede_heatmap_256.png` |



---

### ğŸ”¹ Grad-CAM

| Mapa de Calor Grad-CAM |
| :---: |
| ![Mapa de Calor Grad-CAM](results/Grad-CAM_layers/SAUDAVEIS/imagens/gradcam_leaf%20a1-a3%20ab_0_jpg.png) |
| **LocalizaÃ§Ã£o:** `results/Grad-CAM_layers/...` |

---


# ğŸ‘¥ Autores

### ğŸ”¹ Pedro Marcinoni 

### ğŸ”¹ Leonardo Krauss 

### Projeto desenvolvido para a disciplina IntroduÃ§Ã£o Ã  InteligÃªncia Artificial (CIC/UnB) â€” 2025/2.

---

# ğŸ“š ReferÃªncias

KATAFUCHI, R.; TOKUNAGA, T.
Image-based Plant Disease Diagnosis with Unsupervised Anomaly Detection Based on Reconstructability of Colors.
ğŸ”— https://arxiv.org/pdf/2011.14306

SELVARAJU, R. et al.
Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization.

# ğŸ™ CrÃ©ditos e Agradecimentos

Este projeto utiliza partes substanciais da implementaÃ§Ã£o oficial de **pix2pix** disponibilizada pelo repositÃ³rio:

### PyTorch CycleGAN and pix2pix

por **Jun-Yan Zhu**, **Taesung Park**, apoiado por **Tongzhou Wang**.

ğŸ”— **RepositÃ³rio:** [https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)

O cÃ³digo completo fornece implementaÃ§Ãµes em PyTorch para **CycleGAN** e **pix2pix**, compatÃ­veis com o artigo:

1.  **Image-to-Image Translation with Conditional Adversarial Networks**
    * **Autores:** Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros
    * **ConferÃªncia:** CVPR 2017.

e tambÃ©m:

2.  **Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks**
    * **Autores:** Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros
    * **ConferÃªncia:** ICCV 2017.

### ğŸ“ Como Citar (BibTeX)

Se vocÃª utilizar este trabalho academicamente, considere tambÃ©m citar os autores originais conforme instruÃ­do no repositÃ³rio:

* **CycleGAN BibTeX:** [https://junyanz.github.io/CycleGAN/CycleGAN.txt](https://junyanz.github.io/CycleGAN/CycleGAN.txt)
* **pix2pix BibTeX:** [https://www.cs.cmu.edu/~junyanz/projects/pix2pix/pix2pix.bib](https://www.cs.cmu.edu/~junyanz/projects/pix2pix/pix2pix.bib)

A equipe de autores mantÃ©m documentaÃ§Ã£o Ãºtil, guias de treinamento e notebooks educacionais que auxiliaram no desenvolvimento deste projeto.